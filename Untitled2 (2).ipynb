{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d0d10",
   "metadata": {
    "height": 1031
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IoT PDF Chatbot is ready! Type your question (or 'exit' to quit).\n",
      "\n",
      "Your question: what is iot \n",
      "\n",
      "Answer: IoT stands for Internet of Things, which refers to the network of physical devices, vehicles, appliances, and other items embedded with sensors, software, and network connectivity, which enables these objects to connect and exchange data. It allows for direct integration of the physical world into computer-based systems, resulting in efficiency improvements, economic benefits, and reduced human intervention. Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import openai\n",
    "\n",
    "# Load API key\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Load PDF\n",
    "file_path = \"iot.pdf\"\n",
    "if os.path.isfile(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load()\n",
    "    print(\"PDF loaded successfully.\")\n",
    "    print(pages[0].page_content if pages else \"PDF is empty.\")\n",
    "\n",
    "# Create embeddings + vectorstore\n",
    "persist_directory = 'docs/chroma_iot/'\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "\n",
    "# Define LLM\n",
    "llm = ChatOpenAI(model_name='gpt-4', temperature=0)\n",
    "\n",
    "# Define prompt template\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"], template=template)\n",
    "\n",
    "# Create RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")\n",
    "\n",
    "# Interactive input loop\n",
    "print(\"\\nIoT PDF Chatbot is ready! Type your question (or 'exit' to quit).\")\n",
    "while True:\n",
    "    question = input(\"\\nYour question: \")\n",
    "    if question.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting chatbot. Goodbye!\")\n",
    "        break\n",
    "    result = qa_chain({\"query\": question})\n",
    "    print(\"\\nAnswer:\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d603c9f",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0837fc2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
